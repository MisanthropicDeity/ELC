{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "from nltk.tag import pos_tag # for proper noun\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n",
    "import math\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"C:\\\\Users\\\\jasme\\\\Desktop\\\\summarization_dataset\\\\news_articles\\\\004.txt\"\n",
    "f = open((filename), \"r\")\n",
    "text=f.read() #append each line in the file to a list\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n"
     ]
    }
   ],
   "source": [
    "sent_tokens = nltk.sent_tokenize(text)\n",
    "word_tokens = nltk.word_tokenize(text)\n",
    "word_tokens_lower=[word.lower() for word in word_tokens]\n",
    "stopWords = list(set(stopwords.words(\"english\")))\n",
    "word_tokens_refined=[x for x in word_tokens_lower if x not in stopWords]\n",
    "print(len(word_tokens_refined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = []\n",
    "ps = PorterStemmer()\n",
    "for w in word_tokens_refined:\n",
    "    stem.append(ps.stem(w))\n",
    "word_tokens_refined=stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0])\n"
     ]
    }
   ],
   "source": [
    "# ......................part 1 (cue phrases).................\n",
    "QPhrases=[\"incidentally\", \"example\", \"anyway\", \"furthermore\",\"according\"\n",
    "            \"first\", \"second\", \"then\", \"now\", \"thus\", \"moreover\", \"therefore\", \"hence\", \"lastly\", \"finally\", \"summary\"]\n",
    "\n",
    "cue_phrases={}\n",
    "for sentence in sent_tokens:\n",
    "    cue_phrases[sentence] = 0\n",
    "    word_tokens = nltk.word_tokenize(sentence)\n",
    "    for word in word_tokens:\n",
    "        if word.lower() in QPhrases:\n",
    "            cue_phrases[sentence] += 1\n",
    "maximum_frequency = max(cue_phrases.values())\n",
    "for k in cue_phrases.keys():\n",
    "    try:\n",
    "        cue_phrases[k] = cue_phrases[k] / maximum_frequency\n",
    "        cue_phrases[k]=round(cue_phrases[k],3)\n",
    "    except ZeroDivisionError:\n",
    "        x=0\n",
    "print(cue_phrases.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])\n"
     ]
    }
   ],
   "source": [
    "# .......................part2 (numerical data)...................\n",
    "numeric_data={}\n",
    "for sentence in sent_tokens:\n",
    "    numeric_data[sentence] = 0\n",
    "    word_tokens = nltk.word_tokenize(sentence)\n",
    "    for k in word_tokens:\n",
    "        if k.isdigit():\n",
    "            numeric_data[sentence] += 1\n",
    "maximum_frequency = max(numeric_data.values())\n",
    "for k in numeric_data.keys():\n",
    "    try:\n",
    "        numeric_data[k] = (numeric_data[k]/maximum_frequency)\n",
    "        numeric_data[k] = round(numeric_data[k], 3)\n",
    "    except ZeroDivisionError:\n",
    "        x=0\n",
    "print(numeric_data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([0.9, 0.45, 0.55, 0.95, 1.0, 0.55, 0.25, 1.0, 0.0, 1, 0.25, 1, 1, 0.95, -0.05, 0.8, 0.85, 0.55, 1])\n"
     ]
    }
   ],
   "source": [
    "#....................part3(sentence length)........................\n",
    "sent_len_score={}\n",
    "for sentence in sent_tokens:\n",
    "    sent_len_score[sentence] = 0\n",
    "    word_tokens = nltk.word_tokenize(sentence)\n",
    "    if len(word_tokens) in range(0,10):\n",
    "        sent_len_score[sentence]=1-0.05*(10-len(word_tokens))\n",
    "    elif len(word_tokens) in range(7,20):\n",
    "        sent_len_score[sentence]=1\n",
    "    else:\n",
    "        sent_len_score[sentence]=1-(0.05)*(len(word_tokens)-20)\n",
    "for k in sent_len_score.keys():\n",
    "    sent_len_score[k]=round(sent_len_score[k],4)\n",
    "print(sent_len_score.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([1.0, 0.5, 0.333, 0.25, 0.2, 0.167, 0.143, 0.125, 0.111, 0.1, 0.111, 0.125, 0.143, 0.167, 0.2, 0.25, 0.333, 0.5, 1.0])\n"
     ]
    }
   ],
   "source": [
    "#....................part4(sentence position)........................\n",
    "sentence_position={}\n",
    "d=1\n",
    "no_of_sent=len(sent_tokens)\n",
    "for i in range(no_of_sent):\n",
    "    a=1/d\n",
    "    b=1/(no_of_sent-d+1)\n",
    "    sentence_position[sent_tokens[d-1]]=max(a,b)\n",
    "    d=d+1\n",
    "for k in sentence_position.keys():\n",
    "    sentence_position[k]=round(sentence_position[k],3)\n",
    "print(sentence_position.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([0.589, 0.773, 0.971, 0.639, 0.649, 0.538, 0.956, 0.548, 0.983, 0.457, 1.0, 0.455, 0.405, 0.68, 0.948, 0.518, 0.694, 0.696, 0.292])\n"
     ]
    }
   ],
   "source": [
    "#Create a frequency table to compute the frequency of each word.\n",
    "freqTable = {}\n",
    "for word in word_tokens_refined:    \n",
    "    if word in freqTable:         \n",
    "        freqTable[word] += 1    \n",
    "    else:         \n",
    "        freqTable[word] = 1\n",
    "for k in freqTable.keys():\n",
    "    freqTable[k]= math.log10(1+freqTable[k])\n",
    "#Compute word frequnecy score of each sentence\n",
    "word_frequency={}\n",
    "for sentence in sent_tokens:\n",
    "    word_frequency[sentence]=0\n",
    "    e=nltk.word_tokenize(sentence)\n",
    "    f=[]\n",
    "    for word in e:\n",
    "        f.append(ps.stem(word))\n",
    "    for word,freq in freqTable.items():\n",
    "        if word in f:\n",
    "            word_frequency[sentence]+=freq\n",
    "maximum=max(word_frequency.values())\n",
    "for key in word_frequency.keys():\n",
    "    try:\n",
    "        word_frequency[key]=word_frequency[key]/maximum\n",
    "        word_frequency[key]=round(word_frequency[key],3)\n",
    "    except ZeroDivisionError:\n",
    "        x=0\n",
    "print(word_frequency.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([0.25, 0.0, 0.25, 0.25, 0.25, 1.0, 0.25, 0.0, 0.25, 0.0, 0.25, 0.25, 0.0, 0.5, 0.0, 0.25, 0.0, 0.25, 0.25])\n"
     ]
    }
   ],
   "source": [
    "#........................part 6 (upper cases).................................\n",
    "upper_case={}\n",
    "for sentence in sent_tokens:\n",
    "    upper_case[sentence] = 0\n",
    "    word_tokens = nltk.word_tokenize(sentence)\n",
    "    for k in word_tokens:\n",
    "        if k.isupper():\n",
    "            upper_case[sentence] += 1\n",
    "maximum_frequency = max(upper_case.values())\n",
    "for k in upper_case.keys():\n",
    "    try:\n",
    "        upper_case[k] = (upper_case[k]/maximum_frequency)\n",
    "        upper_case[k] = round(upper_case[k], 3)\n",
    "    except ZeroDivisionError:\n",
    "        x=0\n",
    "print(upper_case.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('High', 'JJ'), ('fuel', 'NN'), ('prices', 'NNS'), ('hit', 'VBD'), (\"BA's\", 'NNP'), ('profits', 'NNS'), ('British', 'NNP'), ('Airways', 'NNP'), ('has', 'VBZ'), ('blamed', 'VBN'), ('high', 'JJ'), ('fuel', 'NN'), ('prices', 'NNS'), ('for', 'IN'), ('a', 'DT'), ('40%', 'CD'), ('drop', 'NN'), ('in', 'IN'), ('profits.', 'NN')]\n",
      "[('Reporting', 'VBG'), ('its', 'PRP$'), ('results', 'NNS'), ('for', 'IN'), ('the', 'DT'), ('three', 'CD'), ('months', 'NNS'), ('to', 'TO'), ('31', 'CD'), ('December', 'NNP'), ('2004,', 'CD'), ('the', 'DT'), ('airline', 'NN'), ('made', 'VBD'), ('a', 'DT'), ('pre-tax', 'JJ'), ('profit', 'NN'), ('of', 'IN'), ('Â£75m', 'NNP'), ('($141m)', 'NNP'), ('compared', 'VBN'), ('with', 'IN'), ('Â£125m', 'NN'), ('a', 'DT'), ('year', 'NN'), ('earlier.', 'NN')]\n",
      "[('Rod', 'NNP'), ('Eddington,', 'NNP'), (\"BA's\", 'NNP'), ('chief', 'NN'), ('executive,', 'NN'), ('said', 'VBD'), ('the', 'DT'), ('results', 'NNS'), ('were', 'VBD'), ('\"respectable\"', 'JJ'), ('in', 'IN'), ('a', 'DT'), ('third', 'JJ'), ('quarter', 'NN'), ('when', 'WRB'), ('fuel', 'NN'), ('costs', 'NNS'), ('rose', 'VBD'), ('by', 'IN'), ('Â£106m', 'NNP'), ('or', 'CC'), ('47.3%.', 'CD')]\n",
      "[(\"BA's\", 'NNP'), ('profits', 'NNS'), ('were', 'VBD'), ('still', 'RB'), ('better', 'JJR'), ('than', 'IN'), ('market', 'NN'), ('expectation', 'NN'), ('of', 'IN'), ('Â£59m,', 'NN'), ('and', 'CC'), ('it', 'PRP'), ('expects', 'VBZ'), ('a', 'DT'), ('rise', 'NN'), ('in', 'IN'), ('full-year', 'JJ'), ('revenues.', 'NN')]\n",
      "[('To', 'TO'), ('help', 'VB'), ('offset', 'VB'), ('the', 'DT'), ('increased', 'JJ'), ('price', 'NN'), ('of', 'IN'), ('aviation', 'NN'), ('fuel,', 'NN'), ('BA', 'NNP'), ('last', 'JJ'), ('year', 'NN'), ('introduced', 'VBD'), ('a', 'DT'), ('fuel', 'NN'), ('surcharge', 'NN'), ('for', 'IN'), ('passengers.', 'NN')]\n",
      "[('In', 'IN'), ('October,', 'NNP'), ('it', 'PRP'), ('increased', 'VBD'), ('this', 'DT'), ('from', 'IN'), ('Â£6', 'NN'), ('to', 'TO'), ('Â£10', 'VB'), ('one-way', 'NN'), ('for', 'IN'), ('all', 'DT'), ('long-haul', 'JJ'), ('flights,', 'NN'), ('while', 'IN'), ('the', 'DT'), ('short-haul', 'JJ'), ('surcharge', 'NN'), ('was', 'VBD'), ('raised', 'VBN'), ('from', 'IN'), ('Â£2.50', 'NN'), ('to', 'TO'), ('Â£4', 'VB'), ('a', 'DT'), ('leg.', 'NN')]\n",
      "[('Yet', 'CC'), ('aviation', 'JJ'), ('analyst', 'NN'), ('Mike', 'NNP'), ('Powell', 'NNP'), ('of', 'IN'), ('Dresdner', 'NNP'), ('Kleinwort', 'NNP'), ('Wasserstein', 'NNP'), ('says', 'VBZ'), (\"BA's\", 'NNP'), ('estimated', 'VBN'), ('annual', 'JJ'), ('surcharge', 'NN'), ('revenues', 'NNS'), ('-', ':'), ('Â£160m', 'SYM'), ('-', ':'), ('will', 'MD'), ('still', 'RB'), ('be', 'VB'), ('way', 'NN'), ('short', 'JJ'), ('of', 'IN'), ('its', 'PRP$'), ('additional', 'JJ'), ('fuel', 'NN'), ('costs', 'NNS'), ('-', ':'), ('a', 'DT'), ('predicted', 'JJ'), ('extra', 'JJ'), ('Â£250m.', 'NN')]\n",
      "[('Turnover', 'NN'), ('for', 'IN'), ('the', 'DT'), ('quarter', 'NN'), ('was', 'VBD'), ('up', 'RB'), ('4.3%', 'CD'), ('to', 'TO'), ('Â£1.97bn,', 'VB'), ('further', 'JJ'), ('benefiting', 'NN'), ('from', 'IN'), ('a', 'DT'), ('rise', 'NN'), ('in', 'IN'), ('cargo', 'NN'), ('revenue.', 'NN')]\n",
      "[('Looking', 'VBG'), ('ahead', 'RB'), ('to', 'TO'), ('its', 'PRP$'), ('full', 'JJ'), ('year', 'NN'), ('results', 'NNS'), ('to', 'TO'), ('March', 'NNP'), ('2005,', 'CD'), ('BA', 'NNP'), ('warned', 'VBD'), ('that', 'IN'), ('yields', 'NNS'), ('-', ':'), ('average', 'JJ'), ('revenues', 'NNS'), ('per', 'IN'), ('passenger', 'NN'), ('-', ':'), ('were', 'VBD'), ('expected', 'VBN'), ('to', 'TO'), ('decline', 'VB'), ('as', 'IN'), ('it', 'PRP'), ('continues', 'VBZ'), ('to', 'TO'), ('lower', 'VB'), ('prices', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('face', 'NN'), ('of', 'IN'), ('competition', 'NN'), ('from', 'IN'), ('low-cost', 'NN'), ('carriers.', 'NN')]\n",
      "[('However,', 'NNP'), ('it', 'PRP'), ('said', 'VBD'), ('sales', 'NNS'), ('would', 'MD'), ('be', 'VB'), ('better', 'JJR'), ('than', 'IN'), ('previously', 'RB'), ('forecast.', 'VB')]\n",
      "[('\"For', 'IN'), ('the', 'DT'), ('year', 'NN'), ('to', 'TO'), ('March', 'NNP'), ('2005,', 'CD'), ('the', 'DT'), ('total', 'JJ'), ('revenue', 'NN'), ('outlook', 'NN'), ('is', 'VBZ'), ('slightly', 'RB'), ('better', 'JJR'), ('than', 'IN'), ('previous', 'JJ'), ('guidance', 'NN'), ('with', 'IN'), ('a', 'DT'), ('3%', 'CD'), ('to', 'TO'), ('3.5%', 'CD'), ('improvement', 'NN'), ('anticipated,\"', 'NN'), ('BA', 'NNP'), ('chairman', 'NN'), ('Martin', 'NNP'), ('Broughton', 'NNP'), ('said.', 'NN')]\n",
      "[('BA', 'NNP'), ('had', 'VBD'), ('previously', 'RB'), ('forecast', 'VBN'), ('a', 'DT'), ('2%', 'CD'), ('to', 'TO'), ('3%', 'CD'), ('rise', 'NN'), ('in', 'IN'), ('full-year', 'JJ'), ('revenue.', 'NN')]\n",
      "[('It', 'PRP'), ('also', 'RB'), ('reported', 'VBD'), ('on', 'IN'), ('Friday', 'NNP'), ('that', 'IN'), ('passenger', 'NN'), ('numbers', 'NNS'), ('rose', 'VBD'), ('8.1%', 'CD'), ('in', 'IN'), ('January.', 'NNP')]\n",
      "[('Aviation', 'NNP'), ('analyst', 'NN'), ('Nick', 'NNP'), ('Van', 'NNP'), ('den', 'JJ'), ('Brul', 'NNP'), ('of', 'IN'), ('BNP', 'NNP'), ('Paribas', 'NNP'), ('described', 'VBD'), (\"BA's\", 'NNP'), ('latest', 'JJS'), ('quarterly', 'JJ'), ('results', 'NNS'), ('as', 'IN'), ('\"pretty', 'JJ'), ('modest\".', 'NN')]\n",
      "[('\"It', 'NN'), ('is', 'VBZ'), ('quite', 'RB'), ('good', 'JJ'), ('on', 'IN'), ('the', 'DT'), ('revenue', 'NN'), ('side', 'NN'), ('and', 'CC'), ('it', 'PRP'), ('shows', 'VBZ'), ('the', 'DT'), ('impact', 'NN'), ('of', 'IN'), ('fuel', 'NN'), ('surcharges', 'NNS'), ('and', 'CC'), ('a', 'DT'), ('positive', 'JJ'), ('cargo', 'NN'), ('development,', 'NN'), ('however,', 'NN'), ('operating', 'NN'), ('margins', 'NNS'), ('down', 'RP'), ('and', 'CC'), ('cost', 'JJ'), ('impact', 'NN'), ('of', 'IN'), ('fuel', 'NN'), ('are', 'VBP'), ('very', 'RB'), ('strong,\"', 'RB'), ('he', 'PRP'), ('said.', 'VB')]\n",
      "[('Since', 'IN'), ('the', 'DT'), ('11', 'CD'), ('September', 'NNP'), ('2001', 'CD'), ('attacks', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('States,', 'NNP'), ('BA', 'NNP'), ('has', 'VBZ'), ('cut', 'VBN'), ('13,000', 'CD'), ('jobs', 'NNS'), ('as', 'IN'), ('part', 'NN'), ('of', 'IN'), ('a', 'DT'), ('major', 'JJ'), ('cost-cutting', 'NN'), ('drive.', 'NN')]\n",
      "[('\"Our', 'JJ'), ('focus', 'NN'), ('remains', 'VBZ'), ('on', 'IN'), ('reducing', 'VBG'), ('controllable', 'JJ'), ('costs', 'NNS'), ('and', 'CC'), ('debt', 'NN'), ('whilst', 'NN'), ('continuing', 'VBG'), ('to', 'TO'), ('invest', 'VB'), ('in', 'IN'), ('our', 'PRP$'), ('products,\"', 'NN'), ('Mr', 'NNP'), ('Eddington', 'NNP'), ('said.', 'NN')]\n",
      "[('\"For', 'JJ'), ('example,', 'NN'), ('we', 'PRP'), ('have', 'VBP'), ('taken', 'VBN'), ('delivery', 'NN'), ('of', 'IN'), ('six', 'CD'), ('Airbus', 'NNP'), ('A321', 'NNP'), ('aircraft', 'NN'), ('and', 'CC'), ('next', 'JJ'), ('month', 'NN'), ('we', 'PRP'), ('will', 'MD'), ('start', 'VB'), ('further', 'JJ'), ('improvements', 'NNS'), ('to', 'TO'), ('our', 'PRP$'), ('Club', 'NNP'), ('World', 'NNP'), ('flat', 'JJ'), ('beds.\"', 'NN')]\n",
      "[(\"BA's\", 'NNP'), ('shares', 'NNS'), ('closed', 'VBD'), ('up', 'RP'), ('four', 'CD'), ('pence', 'NN'), ('at', 'IN'), ('274.5', 'CD'), ('pence.', 'NN')]\n",
      "dict_values([0.429, 0.429, 0.571, 0.143, 0.143, 0.143, 0.857, 0.0, 0.286, 0.143, 0.571, 0.143, 0.286, 1.0, 0.0, 0.571, 0.286, 0.571, 0.143])\n"
     ]
    }
   ],
   "source": [
    "#......................... part7 (number of proper noun)...................\n",
    "proper_noun={}\n",
    "for sentence in sent_tokens:\n",
    "    tagged_sent = pos_tag(sentence.split())\n",
    "    propernouns = [word for word, pos in tagged_sent if pos == 'NNP']\n",
    "    proper_noun[sentence]=len(propernouns)\n",
    "maximum_frequency = max(proper_noun.values())\n",
    "for k in proper_noun.keys():\n",
    "    try:\n",
    "        proper_noun[k] = (proper_noun[k]/maximum_frequency)\n",
    "        proper_noun[k] = round(proper_noun[k], 3)\n",
    "    except ZeroDivisionError:\n",
    "        x=0\n",
    "print(proper_noun.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([1.0, 0.118, 0.235, 0.176, 0.235, 0.059, 0.235, 0.118, 0.118, 0.059, 0.235, 0.176, 0.118, 0.118, 0.176, 0.059, 0.059, 0.118, 0.118])\n"
     ]
    }
   ],
   "source": [
    "#................................. part 8 (word matches with heading) ...................\n",
    "head_match={}\n",
    "heading=sent_tokens[0]\n",
    "for sentence in sent_tokens:\n",
    "    head_match[sentence]=0\n",
    "    word_tokens = nltk.word_tokenize(sentence)\n",
    "    for k in word_tokens:\n",
    "        if k not in stopWords:\n",
    "            k = ps.stem(k)\n",
    "            if k in ps.stem(heading):\n",
    "                head_match[sentence] += 1\n",
    "maximum_frequency = max(head_match.values())\n",
    "for k in head_match.keys():\n",
    "    try:\n",
    "        head_match[k] = (head_match[k]/maximum_frequency)\n",
    "        head_match[k] = round(head_match[k], 3)\n",
    "    except ZeroDivisionError:\n",
    "        x=0\n",
    "print(head_match.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([4.667999999999999, 3.2699999999999996, 2.9099999999999997, 2.408, 2.477, 2.457, 2.691, 1.791, 2.2479999999999998, 1.7590000000000001, 3.4169999999999994, 3.149, 1.952, 3.415, 1.2739999999999998, 3.4479999999999995, 2.222, 3.684999999999999, 2.8029999999999995])\n"
     ]
    }
   ],
   "source": [
    "total_score={}\n",
    "for k in cue_phrases.keys():\n",
    "    total_score[k]=cue_phrases[k]+numeric_data[k]+sent_len_score[k]+sentence_position[k]+word_frequency[k]+upper_case[k]+proper_noun[k]+head_match[k]\n",
    "print(total_score.values())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.739157894736842\n",
      " High fuel prices hit BA's profits\n",
      "\n",
      "British Airways has blamed high fuel prices for a 40% drop in profits. \"For the year to March 2005, the total revenue outlook is slightly better than previous guidance with a 3% to 3.5% improvement anticipated,\" BA chairman Martin Broughton said. Aviation analyst Nick Van den Brul of BNP Paribas described BA's latest quarterly results as \"pretty modest\". Since the 11 September 2001 attacks in the United States, BA has cut 13,000 jobs as part of a major cost-cutting drive. \"For example, we have taken delivery of six Airbus A321 aircraft and next month we will start further improvements to our Club World flat beds.\"\n"
     ]
    }
   ],
   "source": [
    "sumValues = 0\n",
    "for sentence in total_score: \n",
    "    sumValues += total_score[sentence] \n",
    "average = sumValues / len(total_score)\n",
    "print(average)\n",
    "# Storing sentences into our summary. \n",
    "summary = '' \n",
    "for sentence in sent_tokens: \n",
    "    if (sentence in total_score) and (total_score[sentence] > (1.2*average)): \n",
    "        summary += \" \" + sentence \n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
