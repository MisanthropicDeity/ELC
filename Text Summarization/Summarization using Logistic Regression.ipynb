{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "from nltk.tag import pos_tag # for proper noun\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ......................part1: Cue Phrases.................\n",
    "def cue_phrases():\n",
    "    QPhrases=[\"incidentally\", \"example\", \"anyway\", \"furthermore\", \"according\", \"date\", \"because\", \"else\", \"last\",\n",
    "            \"first\", \"second\", \"then\", \"now\", \"thus\", \"moreover\", \"therefore\", \"hence\", \"lastly\", \"finally\", \"summary\", \"january\", \n",
    "              \"february\", \"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\", \"october\", \"november\", \"december\", \n",
    "              \"week\", \"year\", \"month\", \"following\"]\n",
    "\n",
    "    cue_phrases={}\n",
    "    for sentence in sent_tokens:\n",
    "        cue_phrases[sentence] = 0\n",
    "        word_tokens = nltk.word_tokenize(sentence)\n",
    "        for word in word_tokens:\n",
    "            if word.lower() in QPhrases:\n",
    "                cue_phrases[sentence] += 1\n",
    "    maximum_frequency = max(cue_phrases.values())\n",
    "    for k in cue_phrases.keys():\n",
    "        try:\n",
    "            cue_phrases[k] = cue_phrases[k] / maximum_frequency\n",
    "            cue_phrases[k] = round(cue_phrases[k],3)\n",
    "        except ZeroDivisionError:\n",
    "            x=0\n",
    "    return cue_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .......................part2: Numerical Data...................\n",
    "def numeric_data():\n",
    "    numeric_data={}\n",
    "    for sentence in sent_tokens:\n",
    "        numeric_data[sentence] = 0\n",
    "        word_tokens = nltk.word_tokenize(sentence)\n",
    "        for k in word_tokens:\n",
    "            if k.isdigit():\n",
    "                numeric_data[sentence] += 1\n",
    "    maximum_frequency = max(numeric_data.values())\n",
    "    for k in numeric_data.keys():\n",
    "        try:\n",
    "            numeric_data[k] = (numeric_data[k]/maximum_frequency)\n",
    "            numeric_data[k] = round(numeric_data[k], 3)\n",
    "        except ZeroDivisionError:\n",
    "            x=0\n",
    "    return numeric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#....................part3: Sentence length........................\n",
    "def sent_len_score():\n",
    "    sent_len_score={}\n",
    "    for sentence in sent_tokens:\n",
    "        sent_len_score[sentence] = 0\n",
    "        word_tokens = nltk.word_tokenize(sentence)\n",
    "        if len(word_tokens) in range(0,10):\n",
    "            sent_len_score[sentence]=1-0.05*(10-len(word_tokens))\n",
    "        elif len(word_tokens) in range(7,20):\n",
    "            sent_len_score[sentence]=1\n",
    "        else:\n",
    "            sent_len_score[sentence]=1-(0.05)*(len(word_tokens)-20)\n",
    "    for k in sent_len_score.keys():\n",
    "        sent_len_score[k]=round(sent_len_score[k],4)\n",
    "    return sent_len_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#....................part4: Sentence Position........................\n",
    "def sentence_position():\n",
    "    sentence_position={}\n",
    "    d=1\n",
    "    no_of_sent=len(sent_tokens)\n",
    "    for i in range(no_of_sent):\n",
    "        a=1/d\n",
    "        b=1/(no_of_sent-d+1)\n",
    "        sentence_position[sent_tokens[d-1]]=max(a,b)\n",
    "        d=d+1\n",
    "    for k in sentence_position.keys():\n",
    "        sentence_position[k]=round(sentence_position[k],3)\n",
    "    return sentence_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#....................part5: Create a frequency table to compute the frequency of each word.........................\n",
    "def word_frequency():\n",
    "    freqTable = {}\n",
    "    for word in word_tokens_refined:    \n",
    "        if word in freqTable:         \n",
    "            freqTable[word] += 1    \n",
    "        else:         \n",
    "            freqTable[word] = 1\n",
    "    for k in freqTable.keys():\n",
    "        freqTable[k]= math.log10(1+freqTable[k])\n",
    "#Compute word frequnecy score of each sentence\n",
    "    word_frequency={}\n",
    "    for sentence in sent_tokens:\n",
    "        word_frequency[sentence]=0\n",
    "        e=nltk.word_tokenize(sentence)\n",
    "        f=[]\n",
    "        for word in e:\n",
    "            f.append(ps.stem(word))\n",
    "        for word,freq in freqTable.items():\n",
    "            if word in f:\n",
    "                word_frequency[sentence]+=freq\n",
    "    maximum=max(word_frequency.values())\n",
    "    for key in word_frequency.keys():\n",
    "        try:\n",
    "            word_frequency[key]=word_frequency[key]/maximum\n",
    "            word_frequency[key]=round(word_frequency[key],3)\n",
    "        except ZeroDivisionError:\n",
    "            x=0\n",
    "    return word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#........................part6: Upper Cases.................................\n",
    "def upper_case():\n",
    "    upper_case={}\n",
    "    for sentence in sent_tokens:\n",
    "        upper_case[sentence] = 0\n",
    "        word_tokens = nltk.word_tokenize(sentence)\n",
    "        for k in word_tokens:\n",
    "            if k.isupper():\n",
    "                upper_case[sentence] += 1\n",
    "    maximum_frequency = max(upper_case.values())\n",
    "    for k in upper_case.keys():\n",
    "        try:\n",
    "            upper_case[k] = (upper_case[k]/maximum_frequency)\n",
    "            upper_case[k] = round(upper_case[k], 3)\n",
    "        except ZeroDivisionError:\n",
    "            x=0\n",
    "    return upper_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#......................... part7: Number of Proper Noun...................\n",
    "def proper_noun():\n",
    "    proper_noun={}\n",
    "    for sentence in sent_tokens:\n",
    "        tagged_sent = pos_tag(sentence.split())\n",
    "        propernouns = [word for word, pos in tagged_sent if pos == 'NNP']\n",
    "        proper_noun[sentence]=len(propernouns)\n",
    "    maximum_frequency = max(proper_noun.values())\n",
    "    for k in proper_noun.keys():\n",
    "        try:\n",
    "            proper_noun[k] = (proper_noun[k]/maximum_frequency)\n",
    "            proper_noun[k] = round(proper_noun[k], 3)\n",
    "        except ZeroDivisionError:\n",
    "            x=0\n",
    "    return proper_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#................................. part8: Word Matches with Heading...................\n",
    "def head_match():\n",
    "    head_match={}\n",
    "    heading=sent_tokens[0]\n",
    "    for sentence in sent_tokens:\n",
    "        head_match[sentence]=0\n",
    "        word_tokens = nltk.word_tokenize(sentence)\n",
    "        for k in word_tokens:\n",
    "            if k not in stopWords:\n",
    "                k = ps.stem(k)\n",
    "                if k in ps.stem(heading):\n",
    "                    head_match[sentence] += 1\n",
    "    maximum_frequency = max(head_match.values())\n",
    "    for k in head_match.keys():\n",
    "        try:\n",
    "            head_match[k] = (head_match[k]/maximum_frequency)\n",
    "            head_match[k] = round(head_match[k], 3)\n",
    "        except ZeroDivisionError:\n",
    "            x=0\n",
    "    return head_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .......................part9: Date/Time Data...................\n",
    "\n",
    "def datetime_data():\n",
    "    datetime_data={}\n",
    "    for sentence in sent_tokens:\n",
    "        datetime_data[sentence] = len(re.findall(r'\\d+\\S\\d+\\S\\d+', sentence))\n",
    "    maximum_frequency = max(datetime_data.values())\n",
    "    for k in datetime_data.keys():\n",
    "        try:\n",
    "            datetime_data[k] = (datetime_data[k]/maximum_frequency)\n",
    "            datetime_data[k] = round(datetime_data[k], 3)\n",
    "        except ZeroDivisionError:\n",
    "            x=0\n",
    "    return datetime_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .......................part10: Special Sentences Data...................\n",
    "\n",
    "def special_data():\n",
    "    special_data={}\n",
    "    for sentence in sent_tokens:\n",
    "        special_data[sentence] = len(re.findall(r'^(\\\"|\\,\"|\\.\")', sentence))\n",
    "        special_data[sentence] += len(re.findall(r'(\\.\"|\\\",|\\\".)$', sentence))\n",
    "        special_data[sentence] += len(re.findall(r'^(\\~|\\,\"|\\.\")', sentence))\n",
    "    maximum_frequency = max(special_data.values())\n",
    "    for k in special_data.keys():\n",
    "        try:\n",
    "            special_data[k] = (special_data[k]/maximum_frequency)\n",
    "            special_data[k] = round(special_data[k], 3)\n",
    "        except ZeroDivisionError:\n",
    "            x=0\n",
    "    return special_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [cue_score, numeric_score, sentence_length_score, sentence_pos, word_frequency, upper_case_score, proper_noun, heading_match_score, date_time_score, special_score, keys, label]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(columns=['cue_score','numeric_score','sentence_length_score','sentence_pos','word_frequency','upper_case_score','proper_noun','heading_match_score','date_time_score','special_score','keys','label'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict_values'>\n",
      "<class 'dict_values'>\n",
      "<class 'dict_values'>\n",
      "<class 'dict_values'>\n",
      "<class 'dict_values'>\n",
      "<class 'dict_values'>\n",
      "<class 'dict_values'>\n",
      "<class 'dict_values'>\n",
      "<class 'dict_values'>\n",
      "<class 'dict_values'>\n",
      "   cue_score  numeric_score  sentence_length_score  sentence_pos  \\\n",
      "0        0.0            0.0                   0.80         1.000   \n",
      "1        0.0            0.0                  -2.25         0.500   \n",
      "2        0.0            0.0                   1.00         0.333   \n",
      "3        1.0            0.0                  -0.10         0.250   \n",
      "4        0.0            0.0                   1.00         0.200   \n",
      "\n",
      "   word_frequency  upper_case_score  proper_noun  heading_match_score  \\\n",
      "0           0.484               1.0        0.364                0.870   \n",
      "1           1.000               1.0        1.000                1.000   \n",
      "2           0.189               0.0        0.000                0.304   \n",
      "3           0.755               0.0        0.909                0.478   \n",
      "4           0.238               0.0        0.091                0.130   \n",
      "\n",
      "   date_time_score  special_score  \\\n",
      "0              0.0            0.0   \n",
      "1              0.0            0.0   \n",
      "2              0.0            0.0   \n",
      "3              0.0            1.0   \n",
      "4              0.0            0.0   \n",
      "\n",
      "                                                keys  label  \n",
      "0  Success from two leading coronavirus vaccine p...      1  \n",
      "1  The fact that two coronavirus vaccines recentl...      1  \n",
      "2  The studies showed both vaccines provided stro...      0  \n",
      "3  \"With the very good news from Pfizer and Moder...      1  \n",
      "4  While Gates didn't delve into the scientific r...      0  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "path1='C:\\\\Users\\\\gagan\\\\Desktop\\\\Notebooks\\\\Text Summarization\\\\Covid19_dataset\\\\documents\\\\'\n",
    "path2='C:\\\\Users\\\\gagan\\\\Desktop\\\\Notebooks\\\\Text Summarization\\\\Covid19_dataset\\\\summary\\\\'\n",
    "\n",
    "filelist = os.listdir(path1)\n",
    "for file in filelist:\n",
    "    f = open(path1+file, \"r\")\n",
    "    f1=open(path2+file,\"r\")\n",
    "    text=f.read()\n",
    "    text1=f1.read()\n",
    "    sent_tokens = nltk.sent_tokenize(text)\n",
    "    word_tokens = nltk.word_tokenize(text)\n",
    "    sent_tokens1 = nltk.sent_tokenize(text1)\n",
    "    word_tokens1 = nltk.word_tokenize(text1)\n",
    "    word_tokens_lower=[word.lower() for word in word_tokens]\n",
    "    stopWords = list(set(stopwords.words(\"english\")))\n",
    "    word_tokens_refined=[x for x in word_tokens_lower if x not in stopWords]\n",
    "    \n",
    "    cue_score = list(cue_phrases().values())\n",
    "    num_score = list(numeric_data().values())\n",
    "    slen_score = list(sent_len_score().values())\n",
    "    spos_score = list(sentence_position().values())\n",
    "    word_freq = list(word_frequency().values())\n",
    "    upper_score = list(upper_case().values())\n",
    "    noun_score = list(proper_noun().values())\n",
    "    head_match_score = list(head_match().values())\n",
    "    datetime_score = list(datetime_data().values())\n",
    "    spl_score = list(special_data().values())\n",
    "    sen = (list(sent_tokens))[0:len(cue_score)]\n",
    "    \n",
    "    label={}\n",
    "    for sentence in sent_tokens:\n",
    "        label[sentence]=0\n",
    "        for sentence1 in sent_tokens1:\n",
    "            if(sentence==sentence1):\n",
    "                label[sentence]+=1\n",
    "                \n",
    "    labels = list(label.values())\n",
    "    df = df.append(pd.DataFrame({'cue_score': cue_score, 'numeric_score': num_score, 'sentence_length_score': slen_score, 'sentence_pos': spos_score, 'word_frequency': word_freq, 'upper_case_score': upper_score, 'proper_noun': noun_score, 'heading_match_score': head_match_score, 'date_time_score': datetime_score, 'special_score': spl_score, 'keys': sen, 'label': labels}), ignore_index=True)\n",
    "    f.close()\n",
    "    f1.close()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.to_csv('C:\\\\Users\\\\gagan\\\\Desktop\\\\Notebooks\\\\Text Summarization\\\\output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv('C:\\\\Users\\\\jasme\\\\Desktop\\\\summarization_dataset\\\\output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\gagan\\\\Desktop\\\\Notebooks\\\\Text Summarization\\\\output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "training=df[df.columns[0:10]]\n",
    "test=df[df.columns[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(training, test, test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf2 = LogisticRegression(random_state = 0)\n",
    "#Train the model using the training sets\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf2.predict(X_test) \n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'model.sav'\n",
    "pickle.dump(clf2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cue_score  numeric_score  sentence_length_score  sentence_pos  \\\n",
      "0         1.0            1.0                   0.45         1.000   \n",
      "1         0.0            0.0                   0.85         0.500   \n",
      "2         0.0            0.0                   1.00         0.333   \n",
      "3         0.0            0.0                   1.00         0.250   \n",
      "4         0.0            0.0                   0.70         0.200   \n",
      "5         1.0            0.5                   0.90         0.167   \n",
      "6         0.0            0.0                   1.00         0.143   \n",
      "7         0.0            0.5                   0.60         0.125   \n",
      "8         0.0            0.0                   1.00         0.111   \n",
      "9         0.0            0.0                   1.00         0.100   \n",
      "10        1.0            0.0                   1.00         0.091   \n",
      "11        0.0            0.5                   1.00         0.083   \n",
      "12        1.0            0.0                   0.90         0.077   \n",
      "13        1.0            0.0                  -0.05         0.071   \n",
      "14        0.0            0.0                   0.75         0.067   \n",
      "15        0.0            0.0                   1.00         0.062   \n",
      "16        0.0            0.5                   0.95         0.059   \n",
      "17        0.0            0.0                   1.00         0.056   \n",
      "18        1.0            0.5                   0.95         0.056   \n",
      "19        0.0            0.0                   1.00         0.059   \n",
      "20        1.0            0.5                   0.95         0.062   \n",
      "21        0.0            0.0                   1.00         0.067   \n",
      "22        0.0            0.0                   0.70         0.071   \n",
      "23        0.0            0.0                   0.65         0.077   \n",
      "24        0.0            0.0                   0.85         0.083   \n",
      "25        1.0            0.0                   1.00         0.091   \n",
      "26        0.0            0.0                   1.00         0.100   \n",
      "27        0.0            0.0                   1.00         0.111   \n",
      "28        1.0            0.5                   0.90         0.125   \n",
      "29        0.0            0.5                   0.50         0.143   \n",
      "30        0.0            0.5                   1.00         0.167   \n",
      "31        0.0            0.0                   1.00         0.200   \n",
      "32        0.0            0.0                   1.00         0.250   \n",
      "33        0.0            0.0                   1.00         0.333   \n",
      "34        0.0            0.5                   0.95         0.500   \n",
      "35        0.0            0.5                   1.00         1.000   \n",
      "\n",
      "    word_frequency  upper_case_score  proper_noun  heading_match_score  \\\n",
      "0            0.970               0.0        0.333                1.000   \n",
      "1            0.673               0.0        0.167                0.294   \n",
      "2            0.688               0.0        0.167                0.176   \n",
      "3            0.668               0.0        0.083                0.118   \n",
      "4            0.545               0.0        0.083                0.059   \n",
      "5            0.831               0.0        0.250                0.118   \n",
      "6            0.290               0.0        0.500                0.059   \n",
      "7            0.857               0.0        0.083                0.294   \n",
      "8            0.596               0.0        0.250                0.118   \n",
      "9            0.617               0.0        0.083                0.118   \n",
      "10           0.540               0.0        0.000                0.118   \n",
      "11           0.566               0.0        0.167                0.235   \n",
      "12           0.703               0.0        0.500                0.176   \n",
      "13           1.000               1.0        1.000                0.353   \n",
      "14           0.219               0.0        0.000                0.059   \n",
      "15           0.623               1.0        0.083                0.176   \n",
      "16           0.818               0.0        0.250                0.176   \n",
      "17           0.290               1.0        0.083                0.059   \n",
      "18           0.414               0.0        0.083                0.176   \n",
      "19           0.813               0.0        0.167                0.118   \n",
      "20           0.700               0.0        0.167                0.118   \n",
      "21           0.596               0.0        0.083                0.176   \n",
      "22           0.668               1.0        0.167                0.176   \n",
      "23           0.092               0.0        0.000                0.000   \n",
      "24           0.254               0.0        0.000                0.059   \n",
      "25           0.551               0.0        0.000                0.118   \n",
      "26           0.519               0.0        0.167                0.118   \n",
      "27           0.429               0.0        0.167                0.118   \n",
      "28           0.750               0.0        0.083                0.235   \n",
      "29           0.645               0.0        0.000                0.176   \n",
      "30           0.637               0.0        0.250                0.176   \n",
      "31           0.469               0.0        0.333                0.176   \n",
      "32           0.572               0.0        0.083                0.118   \n",
      "33           0.322               0.0        0.000                0.059   \n",
      "34           0.337               0.0        0.083                0.118   \n",
      "35           0.418               0.0        0.250                0.059   \n",
      "\n",
      "   date_time_score special_score  \\\n",
      "0                0             0   \n",
      "1                0             0   \n",
      "2                0             0   \n",
      "3                0             0   \n",
      "4                0             0   \n",
      "5                0             0   \n",
      "6                0             0   \n",
      "7                0             0   \n",
      "8                0             0   \n",
      "9                0             0   \n",
      "10               0             0   \n",
      "11               0             0   \n",
      "12               0             0   \n",
      "13               0             0   \n",
      "14               0             0   \n",
      "15               0             0   \n",
      "16               0             0   \n",
      "17               0             0   \n",
      "18               0             0   \n",
      "19               0             0   \n",
      "20               0             0   \n",
      "21               0             0   \n",
      "22               0             0   \n",
      "23               0             0   \n",
      "24               0             0   \n",
      "25               0             0   \n",
      "26               0             0   \n",
      "27               0             0   \n",
      "28               0             0   \n",
      "29               0             0   \n",
      "30               0             0   \n",
      "31               0             0   \n",
      "32               0             0   \n",
      "33               0             0   \n",
      "34               0             0   \n",
      "35               0             0   \n",
      "\n",
      "                                                 keys  \n",
      "0   Born into a Jewish family on 14th March, 1 879...  \n",
      "1   His father, Hermann Einstein was a salesman an...  \n",
      "2   Albert had a sister, Maja, two years younger t...  \n",
      "3   When Albert was five, his father showed him a ...  \n",
      "4   Albert realised that something in empty space ...  \n",
      "5   In 1889, a family friend named Max Talmud intr...  \n",
      "6   These included Kantâ€™s â€˜Critique of Pure Re...  \n",
      "7   From the latter book, Albert began to understa...  \n",
      "8   In his early teens, Albert attended the new an...  \n",
      "9   His father intended him to pursue electrical e...  \n",
      "10  According to him, the spirit of learning and c...  \n",
      "11  In 1894, when Einstein was fifteen, his father...  \n",
      "12  During this time, he wrote his first scientifi...  \n",
      "13  Now rather than completing high school, Albert...  \n",
      "14                                   He did not pass.  \n",
      "15  So after completing his secondary school, he g...  \n",
      "16  In 1901, Einstein published a paper in the pre...  \n",
      "17  He graduated from ETH with a diploma in teaching.  \n",
      "18     The year 1905 was very fortunate for Einstein.  \n",
      "19  While working in the patent office, he publish...  \n",
      "20  All the four papers are today recognised as tr...  \n",
      "21  These were on photoelectric effect, Brownian m...  \n",
      "22  He deduced the well known equation, E = mcÂ², ...  \n",
      "23                                         This late?  \n",
      "24            laid the foundations of nuclear energy.  \n",
      "25     At first, his papers were not taken seriously.  \n",
      "26  But soon they grabbed the attention of Max Pla...  \n",
      "27  Max invited Einstein to give lectures at inter...  \n",
      "28  In 1906, the patent office promoted Einstein t...  \n",
      "29  In 1910, he wrote a paper that described the c...  \n",
      "30  In 1911, Einstein became an associate professo...  \n",
      "31  However, shortly afterwards, he accepted a ful...  \n",
      "32  Here, he published a paper about the effects o...  \n",
      "33  This paper appealed the astronomers and they s...  \n",
      "34  Einstein completed the theory of relativity in...  \n",
      "35  British astronomer Sir Arthur Eddington confir...  \n"
     ]
    }
   ],
   "source": [
    "df2=pd.DataFrame(columns=['cue_score','numeric_score','sentence_length_score','sentence_pos','word_frequency','upper_case_score','proper_noun','heading_match_score','date_time_score','special_score','keys'])\n",
    "\n",
    "f = open(\"C:\\\\Users\\\\gagan\\\\Desktop\\\\Notebooks\\\\Text Summarization\\\\einstein.txt\", \"r\")\n",
    "text = f.read()\n",
    "\n",
    "sent_tokens = nltk.sent_tokenize(text)\n",
    "word_tokens = nltk.word_tokenize(text)\n",
    "word_tokens_lower=[word.lower() for word in word_tokens]\n",
    "stopWords = list(set(stopwords.words(\"english\")))\n",
    "word_tokens_refined=[x for x in word_tokens_lower if x not in stopWords]\n",
    "\n",
    "cue_score = list(cue_phrases().values())\n",
    "num_score = list(numeric_data().values())\n",
    "slen_score = list(sent_len_score().values())\n",
    "spos_score = list(sentence_position().values())\n",
    "word_freq = list(word_frequency().values())\n",
    "upper_score = list(upper_case().values())\n",
    "noun_score = list(proper_noun().values())\n",
    "head_match_score = list(head_match().values())\n",
    "datetime_score = list(datetime_data().values())\n",
    "spl_score = list(special_data().values())\n",
    "sen = (list(sent_tokens))[0:len(cue_score)]\n",
    "\n",
    "df2 = df2.append(pd.DataFrame({'cue_score': cue_score, 'numeric_score': num_score, 'sentence_length_score': slen_score, 'sentence_pos': spos_score, 'word_frequency': word_freq, 'upper_case_score': upper_score, 'proper_noun': noun_score, 'heading_match_score': head_match_score, 'date_time_score': datetime_score, 'special_score': spl_score, 'keys': sen}), ignore_index=True)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Born into a Jewish family on 14th March, 1 879 in Germany, Einstein had early speech difficultiesâ€”still, he was a topper at the elementary school.In 1889, a family friend named Max Talmud introduced the ten year old Albert to popular science and philosophy texts.Now rather than completing high school, Albert decided to apply directly to the ETH (Eidgenossische Technische Hochschule) itâ€™s in German language thatâ€™s why not written Zurich, the Swiss Federal Institute of Technology in Zurich, Switzerland.\n"
     ]
    }
   ],
   "source": [
    "summary_labels = clf2.predict(df2[df2.columns[0:10]]) \n",
    "summary = \"\"\n",
    "for i in range(len(df2['cue_score'])):\n",
    "    if(summary_labels[i] == 1):\n",
    "        summary += df2[\"keys\"][i]\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
