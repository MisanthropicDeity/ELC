{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "from nltk.tag import pos_tag # for proper noun\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ......................part 1 (cue phrases).................\n",
    "def cue_phrases():\n",
    "    QPhrases=[\"incidentally\", \"example\", \"anyway\", \"furthermore\",\"according\"\n",
    "            \"first\", \"second\", \"then\", \"now\", \"thus\", \"moreover\", \"therefore\", \"hence\", \"lastly\", \"finally\", \"summary\"]\n",
    "\n",
    "    cue_phrases={}\n",
    "    for sentence in sent_tokens:\n",
    "        cue_phrases[sentence] = 0\n",
    "        word_tokens = nltk.word_tokenize(sentence)\n",
    "        for word in word_tokens:\n",
    "            if word.lower() in QPhrases:\n",
    "                cue_phrases[sentence] += 1\n",
    "    maximum_frequency = max(cue_phrases.values())\n",
    "    for k in cue_phrases.keys():\n",
    "        try:\n",
    "            cue_phrases[k] = cue_phrases[k] / maximum_frequency\n",
    "            cue_phrases[k]=round(cue_phrases[k],3)\n",
    "        except ZeroDivisionError:\n",
    "            x=0\n",
    "    return cue_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .......................part2 (numerical data)...................\n",
    "def numeric_data():\n",
    "    numeric_data={}\n",
    "    for sentence in sent_tokens:\n",
    "        numeric_data[sentence] = 0\n",
    "        word_tokens = nltk.word_tokenize(sentence)\n",
    "        for k in word_tokens:\n",
    "            if k.isdigit():\n",
    "                numeric_data[sentence] += 1\n",
    "    maximum_frequency = max(numeric_data.values())\n",
    "    for k in numeric_data.keys():\n",
    "        try:\n",
    "            numeric_data[k] = (numeric_data[k]/maximum_frequency)\n",
    "            numeric_data[k] = round(numeric_data[k], 3)\n",
    "        except ZeroDivisionError:\n",
    "            x=0\n",
    "    return numeric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#....................part3(sentence length)........................\n",
    "def sent_len_score():\n",
    "    sent_len_score={}\n",
    "    for sentence in sent_tokens:\n",
    "        sent_len_score[sentence] = 0\n",
    "        word_tokens = nltk.word_tokenize(sentence)\n",
    "        if len(word_tokens) in range(0,10):\n",
    "            sent_len_score[sentence]=1-0.05*(10-len(word_tokens))\n",
    "        elif len(word_tokens) in range(7,20):\n",
    "            sent_len_score[sentence]=1\n",
    "        else:\n",
    "            sent_len_score[sentence]=1-(0.05)*(len(word_tokens)-20)\n",
    "    for k in sent_len_score.keys():\n",
    "        sent_len_score[k]=round(sent_len_score[k],4)\n",
    "    return sent_len_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#....................part4(sentence position)........................\n",
    "def sentence_position():\n",
    "    sentence_position={}\n",
    "    d=1\n",
    "    no_of_sent=len(sent_tokens)\n",
    "    for i in range(no_of_sent):\n",
    "        a=1/d\n",
    "        b=1/(no_of_sent-d+1)\n",
    "        sentence_position[sent_tokens[d-1]]=max(a,b)\n",
    "        d=d+1\n",
    "    for k in sentence_position.keys():\n",
    "        sentence_position[k]=round(sentence_position[k],3)\n",
    "    return sentence_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a frequency table to compute the frequency of each word.\n",
    "def word_frequency():\n",
    "    freqTable = {}\n",
    "    for word in word_tokens_refined:    \n",
    "        if word in freqTable:         \n",
    "            freqTable[word] += 1    \n",
    "        else:         \n",
    "            freqTable[word] = 1\n",
    "    for k in freqTable.keys():\n",
    "        freqTable[k]= math.log10(1+freqTable[k])\n",
    "#Compute word frequnecy score of each sentence\n",
    "    word_frequency={}\n",
    "    for sentence in sent_tokens:\n",
    "        word_frequency[sentence]=0\n",
    "        e=nltk.word_tokenize(sentence)\n",
    "        f=[]\n",
    "        for word in e:\n",
    "            f.append(ps.stem(word))\n",
    "        for word,freq in freqTable.items():\n",
    "            if word in f:\n",
    "                word_frequency[sentence]+=freq\n",
    "    maximum=max(word_frequency.values())\n",
    "    for key in word_frequency.keys():\n",
    "        try:\n",
    "            word_frequency[key]=word_frequency[key]/maximum\n",
    "            word_frequency[key]=round(word_frequency[key],3)\n",
    "        except ZeroDivisionError:\n",
    "            x=0\n",
    "    return word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#........................part 6 (upper cases).................................\n",
    "def upper_case():\n",
    "    upper_case={}\n",
    "    for sentence in sent_tokens:\n",
    "        upper_case[sentence] = 0\n",
    "        word_tokens = nltk.word_tokenize(sentence)\n",
    "        for k in word_tokens:\n",
    "            if k.isupper():\n",
    "                upper_case[sentence] += 1\n",
    "    maximum_frequency = max(upper_case.values())\n",
    "    for k in upper_case.keys():\n",
    "        try:\n",
    "            upper_case[k] = (upper_case[k]/maximum_frequency)\n",
    "            upper_case[k] = round(upper_case[k], 3)\n",
    "        except ZeroDivisionError:\n",
    "            x=0\n",
    "    return upper_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#......................... part7 (number of proper noun)...................\n",
    "def proper_noun():\n",
    "    proper_noun={}\n",
    "    for sentence in sent_tokens:\n",
    "        tagged_sent = pos_tag(sentence.split())\n",
    "        propernouns = [word for word, pos in tagged_sent if pos == 'NNP']\n",
    "        proper_noun[sentence]=len(propernouns)\n",
    "    maximum_frequency = max(proper_noun.values())\n",
    "    for k in proper_noun.keys():\n",
    "        try:\n",
    "            proper_noun[k] = (proper_noun[k]/maximum_frequency)\n",
    "            proper_noun[k] = round(proper_noun[k], 3)\n",
    "        except ZeroDivisionError:\n",
    "            x=0\n",
    "    return proper_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#................................. part 8 (word matches with heading) ...................\n",
    "def head_match():\n",
    "    head_match={}\n",
    "    heading=sent_tokens[0]\n",
    "    for sentence in sent_tokens:\n",
    "        head_match[sentence]=0\n",
    "        word_tokens = nltk.word_tokenize(sentence)\n",
    "        for k in word_tokens:\n",
    "            if k not in stopWords:\n",
    "                k = ps.stem(k)\n",
    "                if k in ps.stem(heading):\n",
    "                    head_match[sentence] += 1\n",
    "    maximum_frequency = max(head_match.values())\n",
    "    for k in head_match.keys():\n",
    "        try:\n",
    "            head_match[k] = (head_match[k]/maximum_frequency)\n",
    "            head_match[k] = round(head_match[k], 3)\n",
    "        except ZeroDivisionError:\n",
    "            x=0\n",
    "    return head_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cue_score  numeric_score  sentence_length_score  sentence_pos  \\\n",
      "0         0.0            1.0                   0.45         1.000   \n",
      "1         0.0            0.0                   0.85         0.500   \n",
      "2         0.0            0.0                   1.00         0.333   \n",
      "3         0.0            0.0                   1.00         0.250   \n",
      "4         0.0            0.0                   0.70         0.200   \n",
      "5         0.0            0.5                   0.90         0.167   \n",
      "6         0.0            0.0                   1.00         0.143   \n",
      "7         0.0            0.5                   0.60         0.125   \n",
      "8         0.0            0.0                   1.00         0.111   \n",
      "9         0.0            0.0                   1.00         0.100   \n",
      "10        0.0            0.0                   1.00         0.091   \n",
      "11        0.0            0.5                   1.00         0.083   \n",
      "12        0.0            0.0                   0.90         0.077   \n",
      "13        1.0            0.0                  -0.05         0.071   \n",
      "14        0.0            0.0                   0.75         0.067   \n",
      "15        0.0            0.0                   1.00         0.062   \n",
      "16        0.0            0.5                   0.95         0.059   \n",
      "17        0.0            0.0                   1.00         0.056   \n",
      "18        0.0            0.5                   0.95         0.056   \n",
      "19        0.0            0.0                   1.00         0.059   \n",
      "20        1.0            0.5                   0.95         0.062   \n",
      "21        0.0            0.0                   1.00         0.067   \n",
      "22        0.0            0.0                   0.70         0.071   \n",
      "23        0.0            0.0                   0.65         0.077   \n",
      "24        0.0            0.0                   0.85         0.083   \n",
      "25        0.0            0.0                   1.00         0.091   \n",
      "26        0.0            0.0                   1.00         0.100   \n",
      "27        0.0            0.0                   1.00         0.111   \n",
      "28        1.0            0.5                   0.90         0.125   \n",
      "29        0.0            0.5                   0.50         0.143   \n",
      "30        0.0            0.5                   1.00         0.167   \n",
      "31        0.0            0.0                   1.00         0.200   \n",
      "32        0.0            0.0                   1.00         0.250   \n",
      "33        0.0            0.0                   1.00         0.333   \n",
      "34        0.0            0.5                   0.95         0.500   \n",
      "35        0.0            0.5                   1.00         1.000   \n",
      "\n",
      "    upper_case_score  heading_match_score  word_frequency  proper_noun  \\\n",
      "0                0.0                1.000           0.970        0.333   \n",
      "1                0.0                0.294           0.673        0.167   \n",
      "2                0.0                0.176           0.688        0.167   \n",
      "3                0.0                0.118           0.668        0.083   \n",
      "4                0.0                0.059           0.545        0.083   \n",
      "5                0.0                0.118           0.831        0.250   \n",
      "6                0.0                0.059           0.290        0.500   \n",
      "7                0.0                0.294           0.857        0.083   \n",
      "8                0.0                0.118           0.596        0.250   \n",
      "9                0.0                0.118           0.617        0.083   \n",
      "10               0.0                0.118           0.540        0.000   \n",
      "11               0.0                0.235           0.566        0.167   \n",
      "12               0.0                0.176           0.703        0.500   \n",
      "13               1.0                0.353           1.000        1.000   \n",
      "14               0.0                0.059           0.219        0.000   \n",
      "15               1.0                0.176           0.623        0.083   \n",
      "16               0.0                0.176           0.818        0.250   \n",
      "17               1.0                0.059           0.290        0.083   \n",
      "18               0.0                0.176           0.414        0.083   \n",
      "19               0.0                0.118           0.813        0.167   \n",
      "20               0.0                0.118           0.700        0.167   \n",
      "21               0.0                0.176           0.596        0.083   \n",
      "22               1.0                0.176           0.668        0.167   \n",
      "23               0.0                0.000           0.092        0.000   \n",
      "24               0.0                0.059           0.254        0.000   \n",
      "25               0.0                0.118           0.551        0.000   \n",
      "26               0.0                0.118           0.519        0.167   \n",
      "27               0.0                0.118           0.429        0.167   \n",
      "28               0.0                0.235           0.750        0.083   \n",
      "29               0.0                0.176           0.645        0.000   \n",
      "30               0.0                0.176           0.637        0.250   \n",
      "31               0.0                0.176           0.469        0.333   \n",
      "32               0.0                0.118           0.572        0.083   \n",
      "33               0.0                0.059           0.322        0.000   \n",
      "34               0.0                0.118           0.337        0.083   \n",
      "35               0.0                0.059           0.418        0.250   \n",
      "\n",
      "                                                 keys label  \n",
      "0   Born into a Jewish family on 14th March, 1 879...   NaN  \n",
      "1   His father, Hermann Einstein was a salesman an...   NaN  \n",
      "2   Albert had a sister, Maja, two years younger t...   NaN  \n",
      "3   When Albert was five, his father showed him a ...   NaN  \n",
      "4   Albert realised that something in empty space ...   NaN  \n",
      "5   In 1889, a family friend named Max Talmud intr...   NaN  \n",
      "6   These included Kantâ€™s â€˜Critique of Pure Re...   NaN  \n",
      "7   From the latter book, Albert began to understa...   NaN  \n",
      "8   In his early teens, Albert attended the new an...   NaN  \n",
      "9   His father intended him to pursue electrical e...   NaN  \n",
      "10  According to him, the spirit of learning and c...   NaN  \n",
      "11  In 1894, when Einstein was fifteen, his father...   NaN  \n",
      "12  During this time, he wrote his first scientifi...   NaN  \n",
      "13  Now rather than completing high school, Albert...   NaN  \n",
      "14                                   He did not pass.   NaN  \n",
      "15  So after completing his secondary school, he g...   NaN  \n",
      "16  In 1901, Einstein published a paper in the pre...   NaN  \n",
      "17  He graduated from ETH with a diploma in teaching.   NaN  \n",
      "18     The year 1905 was very fortunate for Einstein.   NaN  \n",
      "19  While working in the patent office, he publish...   NaN  \n",
      "20  All the four papers are today recognised as tr...   NaN  \n",
      "21  These were on photoelectric effect, Brownian m...   NaN  \n",
      "22  He deduced the well known equation, E = mcÂ², ...   NaN  \n",
      "23                                         This late?   NaN  \n",
      "24            laid the foundations of nuclear energy.   NaN  \n",
      "25     At first, his papers were not taken seriously.   NaN  \n",
      "26  But soon they grabbed the attention of Max Pla...   NaN  \n",
      "27  Max invited Einstein to give lectures at inter...   NaN  \n",
      "28  In 1906, the patent office promoted Einstein t...   NaN  \n",
      "29  In 1910, he wrote a paper that described the c...   NaN  \n",
      "30  In 1911, Einstein became an associate professo...   NaN  \n",
      "31  However, shortly afterwards, he accepted a ful...   NaN  \n",
      "32  Here, he published a paper about the effects o...   NaN  \n",
      "33  This paper appealed the astronomers and they s...   NaN  \n",
      "34  Einstein completed the theory of relativity in...   NaN  \n",
      "35  British astronomer Sir Arthur Eddington confir...   NaN  \n"
     ]
    }
   ],
   "source": [
    "df2=pd.DataFrame(columns=['cue_score','numeric_score','sentence_length_score','sentence_pos','upper_case_score','heading_match_score','word_frequency','proper_noun','keys','label'])\n",
    "f = open(\"C:\\\\Users\\\\gagan\\\\Desktop\\\\Notebooks\\\\Text Summarization\\\\einstein.txt\", \"r\")\n",
    "text = f.read()\n",
    "sent_tokens = nltk.sent_tokenize(text)\n",
    "word_tokens = nltk.word_tokenize(text)\n",
    "word_tokens_lower=[word.lower() for word in word_tokens]\n",
    "stopWords = list(set(stopwords.words(\"english\")))\n",
    "word_tokens_refined=[x for x in word_tokens_lower if x not in stopWords]\n",
    "g=cue_phrases()\n",
    "z=list(g.keys())\n",
    "g=list(g.values())\n",
    "h=numeric_data()\n",
    "h=list(h.values())\n",
    "\n",
    "i=sent_len_score()\n",
    "i=list(i.values())\n",
    "\n",
    "j=sentence_position()\n",
    "j=list(j.values())   \n",
    "\n",
    "p=upper_case()\n",
    "p=list(p.values())\n",
    "\n",
    "l=head_match()\n",
    "l=list(l.values())\n",
    "\n",
    "m=word_frequency()\n",
    "m=list(m.values())\n",
    "\n",
    "n=proper_noun()\n",
    "n=list(n.values())\n",
    "\n",
    "df2 = df2.append(pd.DataFrame({'cue_score': g,'numeric_score': h,'sentence_length_score': i,'sentence_pos': j,'upper_case_score': p,'heading_match_score': l,'word_frequency': m,'proper_noun': n,'keys': z}), ignore_index=True)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('model.sav', 'rb'))\n",
    "\n",
    "summary_labels = model.predict(df2[df2.columns[0:8]]) \n",
    "print(summary_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albert had a sister, Maja, two years younger to him.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df2['label'])):\n",
    "    df2['label'][i] = summary_labels[i]\n",
    "print(df2[\"keys\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Born into a Jewish family on 14th March, 1 879 in Germany, Einstein had early speech difficultiesâ€”still, he was a topper at the elementary school.Now rather than completing high school, Albert decided to apply directly to the ETH (Eidgenossische Technische Hochschule) itâ€™s in German language thatâ€™s why not written Zurich, the Swiss Federal Institute of Technology in Zurich, Switzerland.All the four papers are today recognised as tremendous achievements and hence, 1905 is known as Einsteinâ€™s â€˜Wonderful yearâ€™.In 1906, the patent office promoted Einstein to technical examiner second class, but he did not give up academia.British astronomer Sir Arthur Eddington confirmed his theory during the solar eclipse of 1919.\n"
     ]
    }
   ],
   "source": [
    "str = \"\"\n",
    "for i in range(len(df2['label'])):\n",
    "    if(df2[\"label\"][i] == 1):\n",
    "        str = str + df2[\"keys\"][i]\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
